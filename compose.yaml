services:
  llm:
    image: vllm/vllm-openai:latest
    ports:
      - 8000:8000
    volumes:
      - ./model/LLM:/model
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command:
      ["/model", "--gpu-memory-utilization", "0.5", "--max-model-len", "5K"]

  emb:
    image: vllm/vllm-openai:latest
    ports:
      - 8001:8001
    volumes:
      - ./model/EMB:/model
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command:
      ["/model", "--gpu-memory-utilization", "0.4", "--max-model-len", "5K"]
networks:
  default:
    external: true
    name: ai_net
